# Nela - Multi-Tenant AI Agent

**Created in 2026 by Bytelink Technologies** to help their clients get responses from their documents.

**Nela** is a high-performance, CPU-optimized FastAPI-based multi-tenant AI agent that helps users **create, manage, and use AI** to get results from their documents. 

## What is Nela?

Nela is a comprehensive multi-tenant platform that enables users to:
- **Create**: Upload and organize documents in a secure, isolated environment
- **Manage**: Track, organize, and manage all your documents with ease
- **Use AI**: Get intelligent answers and insights from your documents using advanced RAG (Retrieval-Augmented Generation) technology

Built with modern architecture supporting multiple tenants, each user's data is completely isolated and secure.

## ğŸš€ Quick Start (3 Commands)

### Prerequisites
- Python 3.13+
- PostgreSQL running on localhost:5432
- Redis running on localhost:6379
- Ollama running on localhost:11434 with `llama3.2` and `mxbai-embed-large:335m` models loaded

### Setup & Run

```bash
# 1. Install dependencies (from server directory)
cd server
pip install -r requirements.txt

# 2. Initialize database
python -c "from App.models import Base; from App.models.DB import engine; Base.metadata.create_all(engine)"

# 3. Start the server
./start.sh
```

Server runs on `http://localhost:8000`

---

## ğŸ“‹ System Architecture

### Core Components

| Component | Technology | Purpose | Port |
|-----------|-----------|---------|------|
| **API Server** | FastAPI 0.127.0 | REST endpoints, request handling | 8001 |
| **Database** | PostgreSQL + SQLAlchemy | User/document metadata, async ORM | 5432 |
| **Vector DB** | ChromaDB 0.5.11 | Document embeddings, semantic search | Local |
| **LLM** | Ollama (llama3.2) | Answer generation | 11434 |
| **Embeddings** | Ollama (mxbai-embed-large) | Vector generation | 11434 |
| **Keyword Search** | BM25 (rank-bm25) | Hybrid search support | In-memory |
| **Cache Layer** | Redis 5.2.0 | Query caching, user sessions | 6379 |

### Deployment Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FastAPI Server                          â”‚
â”‚                    (localhost:8001)                             â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  Auth Router â”‚  â”‚  User Router â”‚  â”‚   AI Router      â”‚     â”‚
â”‚  â”‚  (OAuth2)    â”‚  â”‚  (CRUD ops)  â”‚  â”‚ (Query/Upload)   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                 â”‚                    â”‚                â”‚
â”‚         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                â”‚
â”‚         â–¼                 â–¼                    â–¼                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚          AI Controller (Business Logic)          â”‚          â”‚
â”‚  â”‚  â€¢ Document Processing (PDF extraction)         â”‚          â”‚
â”‚  â”‚  â€¢ Chunk Management (overlap handling)          â”‚          â”‚
â”‚  â”‚  â€¢ User Isolation (per-user filtering)         â”‚          â”‚
â”‚  â”‚  â€¢ Hybrid Search (BM25 + vector)               â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚           â”‚                  â”‚                                 â”‚
â”‚      â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚      â”‚ PostgreSQLâ”‚      â”‚  ChromaDB         â”‚                â”‚
â”‚      â”‚ (metadata)â”‚      â”‚  (embeddings)     â”‚                â”‚
â”‚      â”‚ localhost â”‚      â”‚  /server/Config/  â”‚                â”‚
â”‚      â”‚ :5432     â”‚      â”‚  DB/chroma_db/    â”‚                â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                              â”‚
         â”‚                              â”‚
         â–¼                              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Redis    â”‚           â”‚   Ollama API       â”‚
    â”‚ Cache    â”‚           â”‚   localhost:11434  â”‚
    â”‚ :6379    â”‚           â”‚  â€¢ llama3.2 (LLM) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚  â€¢ Embeddings     â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### File Structure

```
server/
â”œâ”€â”€ main.py                    # FastAPI app initialization
â”œâ”€â”€ requirements.txt           # Python dependencies (CPU-only)
â”œâ”€â”€ start.sh                   # Server startup script
â”œâ”€â”€ upload/                    # User uploaded files directory
â”‚   â”œâ”€â”€ {user_id_1}/          # Files for user 1
â”‚   â”‚   â”œâ”€â”€ document1.pdf
â”‚   â”‚   â””â”€â”€ report.txt
â”‚   â””â”€â”€ {user_id_2}/          # Files for user 2
â”‚       â””â”€â”€ analysis.pdf
â”œâ”€â”€ App/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ AI_router.py       # /api/v1/upload, /api/v1/ai/prompt
â”‚   â”‚   â”œâ”€â”€ Auth.py            # OAuth2 authentication
â”‚   â”‚   â””â”€â”€ User_router.py     # User CRUD endpoints
â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”œâ”€â”€ AI_controller.py   # Ollama integration, ChromaDB queries
â”‚   â”‚   â””â”€â”€ User_controller.py # User operations
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ User_model.py      # SQLAlchemy User ORM
â”‚   â”‚   â””â”€â”€ Document_model.py  # SQLAlchemy Document ORM
â”‚   â”œâ”€â”€ schema/
â”‚   â”‚   â””â”€â”€ Document_schema.py # Pydantic schemas (QueryRequest, etc.)
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ file_manager.py    # â­ File storage management (NEW)
â”‚   â””â”€â”€ enums.py               # Enums (DocumentType, etc.)
â”œâ”€â”€ Config/
â”‚   â”œâ”€â”€ DB/
â”‚   â”‚   â”œâ”€â”€ chroma_db/         # â­ SINGLE ChromaDB location
â”‚   â”‚   â””â”€â”€ DB.py              # Database connection config
â”‚   â”œâ”€â”€ Redis/
â”‚   â”‚   â””â”€â”€ Redis_client.py    # Redis configuration
â”‚   â””â”€â”€ Security/
â”‚       â””â”€â”€ oauth.py           # OAuth2 settings
â””â”€â”€ Test/
    â””â”€â”€ db_conn_test.py        # Connection verification
```
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ User_model.py      # SQLAlchemy User ORM
â”‚   â”‚   â””â”€â”€ Document_model.py  # SQLAlchemy Document ORM
â”‚   â”œâ”€â”€ schema/
â”‚   â”‚   â””â”€â”€ Document_schema.py # Pydantic schemas (QueryRequest, etc.)
â”‚   â””â”€â”€ enums.py               # Enums (DocumentType, etc.)
â”œâ”€â”€ Config/
â”‚   â”œâ”€â”€ DB/
â”‚   â”‚   â”œâ”€â”€ chroma_db/         # â­ SINGLE ChromaDB location
â”‚   â”‚   â””â”€â”€ DB.py              # Database connection config
â”‚   â”œâ”€â”€ Redis/
â”‚   â”‚   â””â”€â”€ Redis_client.py    # Redis configuration
â”‚   â””â”€â”€ Security/
â”‚       â””â”€â”€ oauth.py           # OAuth2 settings
â””â”€â”€ Test/
    â””â”€â”€ db_conn_test.py        # Connection verification
```

---

## ğŸ”Œ API Endpoints

### Upload Documents

**POST** `/api/v1/upload`

Upload a PDF document for processing and indexing.

```bash
curl -X POST http://localhost:8000/api/v1/upload \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -F "file=@document.pdf"
```

**Response:**
```json
{
  "document_id": "550e8400-e29b-41d4-a716-446655440000",
  "filename": "document.pdf",
  "pages": 15,
  "chunks": 42,
  "status": "indexed"
}
```

### Query Documents

**POST** `/api/v1/ai/prompt`

Query your documents with intelligent RAG-based retrieval.

```bash
curl -X POST http://localhost:8000/api/v1/ai/prompt \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "What are the main findings?",
    "user_id": "optional_user_id_for_testing"
  }'
```

**Response:**
```json
{
  "answer": "Based on the documents, the main findings are...",
  "sources": [
    {
      "document": "report.pdf",
      "page": 5,
      "chunk": "Relevant excerpt from the document..."
    }
  ],
  "processing_time_ms": 2800
}
```

#### Optional Parameter: `user_id`

For testing with different user documents, you can override the user_id:

```bash
curl -X POST http://localhost:8000/api/v1/ai/prompt \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Your question here",
    "user_id": "test_user_123"
  }'
```

This is useful for debugging user-specific document retrieval.

### List User Files

**GET** `/api/v1/ai/files`

List all files uploaded by the current user.

```bash
curl -X GET http://localhost:8000/api/v1/ai/files \
  -H "Authorization: Bearer YOUR_TOKEN"
```

**Response:**
```json
{
  "file_count": 3,
  "total_size_mb": 45.6,
  "files": ["report.pdf", "analysis.txt", "data.csv"],
  "storage_location": "upload/550e8400-e29b-41d4-a716-446655440000/",
  "message": "User has 3 files using 45.6 MB"
}
```

### Get Storage Information

**GET** `/api/v1/ai/storage/info`

Get detailed storage information for the current user.

```bash
curl -X GET http://localhost:8000/api/v1/ai/storage/info \
  -H "Authorization: Bearer YOUR_TOKEN"
```

**Response:**
```json
{
  "user_id": "550e8400-e29b-41d4-a716-446655440000",
  "file_count": 3,
  "total_size_bytes": 47852544,
  "total_size_mb": 45.6,
  "files": ["report.pdf", "analysis.txt", "data.csv"],
  "upload_directory": "/home/user/server/upload/550e8400-e29b-41d4-a716-446655440000/"
}
```

---

## ğŸ“ Data Storage & Isolation

### Upload Directory Structure (NEW)
**Files are stored in user-based directories:** `/server/upload/{user_id}/`

Each uploaded file is automatically organized into its own user directory:
```
server/upload/
â”œâ”€â”€ 550e8400-e29b-41d4-a716-446655440000/    # User 1
â”‚   â”œâ”€â”€ report.pdf
â”‚   â”œâ”€â”€ analysis.txt
â”‚   â””â”€â”€ whitepaper.md
â””â”€â”€ 660e8400-e29b-41d4-a716-446655440001/    # User 2
    â”œâ”€â”€ document.pdf
    â””â”€â”€ summary.txt
```

**Features:**
- âœ… Automatic directory creation per user
- âœ… File path tracked in PostgreSQL (`documents.file_path`)
- âœ… Complete user isolation (files only in their directory)
- âœ… Easy backup and recovery per user
- âœ… Security: No path traversal attacks (filenames sanitized)

### ChromaDB Location
**Single, centralized location:** `/server/Config/DB/chroma_db/`

All documents, embeddings, and metadata are stored in this directory. Backup this directory to preserve all document data.

### User Isolation

Every document is stored with a `user_id` metadata field in multiple locations:

1. **File System:** `server/upload/{user_id}/{filename}`
2. **Database:** PostgreSQL `documents.file_path` and `documents.user_id`
3. **Vector Store:** ChromaDB metadata `{"user_id": user.id}`

```python
# Documents are stored with: {"user_id": user.id}
# Queries filter by: where={"user_id": {"$eq": current_user_id}}
# Files stored in: server/upload/{user_id}/{filename}
```

**Features:**
- âœ… Complete user isolation (can't access other users' documents or files)
- âœ… Multi-user safe
- âœ… Per-user search results
- âœ… Per-user file storage
- âœ… Supports testing with `user_id` parameter

### Hybrid Search Strategy

1. **Vector Search** (Semantic)
   - Uses `mxbai-embed-large:335m` embeddings
   - Semantic similarity matching
   - Returns top 5 most relevant chunks

2. **BM25 Keyword Search** (Lexical)
   - Exact keyword matching
   - Combines with vector results
   - Handles technical terms better

3. **Fusion** (Combined)
   - Reranks results from both methods
   - Better accuracy than either alone

---

## âš¡ Performance Characteristics

### Startup Time
- **Cold Start:** ~3.2 seconds
- **Server Ready:** All services initialized
- **No GPU required:** CPU-only deployment

### Query Performance
- **First Query (cold):** ~2,800 ms
  - Ollama embedding generation
  - ChromaDB similarity search
  - LLM answer generation
  
- **Subsequent Queries (Redis cached):** ~5 ms
  - Direct retrieval from Redis

### Resource Usage
- **Memory:** ~800 MB base + 200 MB per active embedding model
- **CPU:** 2-4 cores typical usage
- **Disk:** ~500 MB for ChromaDB with 50+ documents
- **Upload Storage:** Varies per uploaded files (files stored in `server/upload/`)

---

## ğŸ” Security & Authentication

### OAuth2 Bearer Token

All endpoints (except health checks) require a valid JWT token:

```
Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
```

### Token Verification

Tokens are validated via:
1. JWT signature verification
2. User existence check in PostgreSQL
3. Token expiration validation

### User Data Protection

- Each user can only access their own documents
- PostgreSQL enforces relational integrity
- ChromaDB filters results by user_id
- Redis sessions are user-specific

---

## ğŸ› Troubleshooting

### Problem: Server won't start

**Error:** `OSError: [Errno 28] No space left on device` or file watch errors

**Solution:**
```bash
# Check system limits
cat /proc/sys/fs/inotify/max_user_watches

# Increase if needed (Linux)
echo "fs.inotify.max_user_watches=524288" | sudo tee -a /etc/sysctl.conf
sudo sysctl -p
```

The `start.sh` script already has `--reload` disabled to prevent file watch issues.

### Problem: "No documents found" when querying

**Symptom:** Successful upload but query returns empty results

**Root Cause:** User ID mismatch (your JWT token user â‰  document owner)

**Solution:** Use the optional `user_id` parameter to test:

```bash
# First, find what user_id your documents are stored under
# Then query with that user_id:
curl -X POST http://localhost:8000/api/v1/ai/prompt \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Your question",
    "user_id": "your_document_user_id"
  }'
```

Check PostgreSQL to verify:
```sql
SELECT id, username FROM users;
SELECT user_id FROM documents;
```

### Problem: Ollama not responding

**Error:** `HTTPError: 500` when querying

**Solution:**
1. Verify Ollama is running: `curl http://localhost:11434/api/tags`
2. Ensure models are loaded:
   ```bash
   ollama pull llama3.2
   ollama pull mxbai-embed-large:335m
   ```
3. Check Ollama memory: Models need ~3-4 GB RAM combined

### Problem: PostgreSQL connection refused

**Error:** `psycopg2.OperationalError: connection refused`

**Solution:**
```bash
# Check PostgreSQL is running
psql -U postgres -h localhost -c "SELECT version();"

# If not running, start it:
sudo systemctl start postgresql

# Verify database exists
psql -U postgres -l | grep statistics
```

### Problem: ChromaDB empty despite uploads

**Solution:** Verify ChromaDB location is correct:

```bash
# Check if data exists
ls -lah /home/kwola/Documents/ai_projects/statistics_analyist_agent/server/Config/DB/chroma_db/

# Should contain:
# - chroma.sqlite3 (main database)
# - 0/ (vector data directory)
```

---

## ğŸ“Š Key Files & Dependencies

### Critical Dependencies

| Package | Version | Purpose |
|---------|---------|---------|
| fastapi | 0.127.0 | Web framework |
| sqlalchemy | 2.0.45 | ORM |
| asyncpg | 0.29.0 | PostgreSQL async driver |
| chromadb | 0.5.11 | Vector database |
| requests | 2.31.0 | HTTP client (Ollama) |
| PyPDF2 | 3.0.1 | PDF processing |
| rank-bm25 | 0.2.2 | Keyword search |
| faiss-cpu | 1.13.2 | Vector operations |
| redis | 5.2.0 | Caching |
| pydantic | 2.7.1 | Data validation |

### Install with
```bash
cd server
pip install -r requirements.txt
```

**Note:** CPU-only optimized. No GPU/CUDA dependencies.

---

## ğŸ”„ System Configuration

### Environment Variables

Create `.env` in server directory:

```env
# Database
DATABASE_URL=postgresql+asyncpg://user:password@localhost/statistics_db
REDIS_URL=redis://localhost:6379

# API
API_PORT=8000
DEBUG=false

# Ollama
OLLAMA_BASE_URL=http://localhost:11434

# Security
SECRET_KEY=your-secret-key-here
ALGORITHM=HS256
```

### Database Schema

**Users Table:**
```sql
CREATE TABLE users (
    id UUID PRIMARY KEY,
    username VARCHAR(255) UNIQUE,
    email VARCHAR(255) UNIQUE,
    password_hash VARCHAR(255),
    created_at TIMESTAMP DEFAULT NOW()
);
```

**Documents Table:**
```sql
CREATE TABLE documents (
    id UUID PRIMARY KEY,
    user_id UUID REFERENCES users(id),
    filename VARCHAR(255),
    file_path VARCHAR(500),
    total_chunks INT,
    created_at TIMESTAMP DEFAULT NOW()
);
```

---

## ğŸ“ˆ Development Notes

### Adding New Models

1. Create model in `App/models/`
2. Add schema in `App/schema/`
3. Create controller in `App/controllers/`
4. Add router in `App/api/`

### Modifying ChromaDB Queries

All ChromaDB operations in `App/controllers/AI_controller.py`:

```python
# Always filter by user_id for isolation
results = collection.query(
    query_embeddings=[embedding],
    n_results=5,
    where={"user_id": {"$eq": user_id}}  # â­ Critical
)
```

### Adding New Endpoints

Register in `main.py`:

```python
from App.api import YourRouter
app.include_router(YourRouter.router, prefix="/api/v1", tags=["your_tag"])
```

---

## ğŸš¢ Deployment Checklist

- [ ] PostgreSQL running and accessible
- [ ] Redis running and accessible
- [ ] Ollama running with required models
- [ ] Python 3.13+ installed
- [ ] Dependencies installed: `pip install -r requirements.txt`
- [ ] `.env` file configured
- [ ] Database initialized
- [ ] Server started: `./start.sh`
- [ ] Health check: `curl http://localhost:8000/health`
- [ ] Test upload works
- [ ] Test query works
- [ ] Check ChromaDB location: `/server/Config/DB/chroma_db/`

---

## ğŸ“ Support & Known Issues

### Known Limitations

1. **Single-machine deployment** - Not distributed
2. **No GPU support** - CPU-only (intentional for flexibility)
3. **PDF only** - Currently supports PDF uploads only
4. **English only** - Models trained for English

### Future Improvements

- [ ] Multi-format document support (DOCX, TXT, HTML)
- [ ] Multi-language support
- [ ] Distributed ChromaDB with replication
- [ ] Advanced caching strategies
- [ ] Real-time document indexing
- [ ] Streaming response support

---

## ğŸ“ Version History

- **v1.0** - Initial release
  - FastAPI server with OAuth2
  - ChromaDB-based document indexing
  - Ollama LLM integration
  - Redis caching
  - User isolation
  - Hybrid search (BM25 + vector)
  - CPU-only optimization

---

**Last Updated:** 2024
**Python Version:** 3.13.7
**ChromaDB Location:** `/server/Config/DB/chroma_db/`
